{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ffa0c0f",
   "metadata": {},
   "source": [
    "# NLP Practice Assignments\n",
    "Day 4\n",
    "    Create Your Own Spell Checker\n",
    "    Objective: Creating a spell checker, correct the incorrect word in the given sentence.\n",
    "    \n",
    "    Problem Statement: While typing or sending any message to person, we generally make \n",
    "    \n",
    "    spelling mistakes. Write a script which will correct the misspelled words in a sentence.\n",
    "    \n",
    "    The input will be a raw string and the output will be a string with the case normalized \n",
    "    and the incorrect word corrected.\n",
    "    \n",
    "    Domain: General\n",
    "    \n",
    "    Analysis to be done: Words availability in corpus\n",
    "    \n",
    "    Content: \n",
    "    Dataset: None\n",
    "    We will be using NLTK’s inbuilt corpora (words, stop words etc.) and no specific dataset.\n",
    "    \n",
    "    Steps to perform:\n",
    "    While there are several approaches to correct spelling , you will use the Levenshtein or \n",
    "    Edit distance approach. \n",
    "    \n",
    "    The approach will be straightforward for correcting a word: \n",
    "        ▪ If the word is present in a list of valid words, the word is correct.\n",
    "        ▪ If the word is absent from the valid word list, we will find the correct \n",
    "    word, i.e., the word from the valid word list which has the lowest edit \n",
    "    distance from the target word.\n",
    "    \n",
    "    Once you define a function, you will iterate over the terms in the given sentence, \n",
    "    correct the words identified as incorrect, and return a joined string with all the terms. \n",
    "    To help speed up execution, you won’t be applying the spell check on the stop words\n",
    "    and punctuation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d45d4831",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to C:\\Users\\Abhisek\n",
      "[nltk_data]     Das\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Sentence: Ths sentece has sme spelng mistkes. Wll ths wrk?\n",
      "Corrected Sentence: The sentence his sie sprang misken . Will the wro ?\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import words\n",
    "from nltk.metrics import edit_distance\n",
    "import string\n",
    "\n",
    "# Download NLTK resources (if not already downloaded)\n",
    "nltk.download('words')\n",
    "# Use a simplified set of valid English words for demonstration\n",
    "valid_words = {\"the\", \"quick\", \"brown\", \"fox\", \"jumps\", \"over\", \"lazy\", \"dog\", \"will\", \"work\"}\n",
    "\n",
    "\n",
    "def is_valid_word(word):\n",
    "    return word.lower() in valid_words\n",
    "\n",
    "# Get the set of valid English words\n",
    "valid_words = set(words.words())\n",
    "\n",
    "def is_valid_word(word):\n",
    "    # Check if the word is a valid English word\n",
    "    return word.lower() in valid_words\n",
    "\n",
    "def correct_spelling(word):\n",
    "    # If the word is valid, return it as is\n",
    "    if is_valid_word(word):\n",
    "        return word\n",
    "\n",
    "    # Find the correct word with the lowest edit distance\n",
    "    suggestions = [w for w in valid_words if w[0].lower() == word[0].lower()]\n",
    "    \n",
    "    if not suggestions:\n",
    "        return word  # No suggestions, return the original word\n",
    "    \n",
    "    corrected_word = min(suggestions, key=lambda w: edit_distance(word, w))\n",
    "    return corrected_word\n",
    "\n",
    "def spell_checker(sentence):\n",
    "    # Tokenize the sentence\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "\n",
    "    # Correct the spelling of each word in the sentence\n",
    "    corrected_words = [correct_spelling(word) if word not in string.punctuation else word for word in words]\n",
    "\n",
    "    # Join the corrected words to form the final corrected sentence\n",
    "    corrected_sentence = ' '.join(corrected_words)\n",
    "\n",
    "    return corrected_sentence\n",
    "\n",
    "# Example usage:\n",
    "input_sentence = \"Ths sentece has sme spelng mistkes. Wll ths wrk?\"\n",
    "output_sentence = spell_checker(input_sentence)\n",
    "print(\"Input Sentence:\", input_sentence)\n",
    "print(\"Corrected Sentence:\", output_sentence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eceac99b",
   "metadata": {},
   "source": [
    "# Tasks: \n",
    "    1. Get a list of valid words in the English language using NLTK’s list of words (Hint:\n",
    "    \n",
    "    use nltk.download(‘words’) to get the raw list.\n",
    "    2. Look at the first 20 words in the list. Is the casing normalized?\n",
    "    \n",
    "    3. Normalize the casing for all the terms.\n",
    "    \n",
    "    4. Some duplicates would have been induced, create unique list after normalizing.\n",
    "   \n",
    "    5. Create a list of stop words which should include: \n",
    "    i. Stop words from NLTK\n",
    "    ii. All punctuations (Hint: use ‘punctuation’ from string module)\n",
    "    iii. Final list should be a combination of these two\n",
    "    \n",
    "    6. Define a function to get correct a single term\n",
    "    • For a given term, find its edit distance with each term in the valid word \n",
    "    list. To speed up execution, you can use the first 20,000 entries in the \n",
    "    valid word list.\n",
    "    • Store the result in a dictionary, the key as the term, and edit distance as \n",
    "    value.\n",
    "    • Sort the dictionary in ascending order of the values.\n",
    "    • Return the first entry in the sorted result (value with minimum edit \n",
    "    distance).\n",
    "    • Using the function, get the correct word for committee.\n",
    "    \n",
    "    7. Make a set from the list of valid words, for faster lookup to see if word is in valid list or not.\n",
    "    \n",
    "    8. Define a function for spelling correction in any given input sentence:\n",
    "    \n",
    "    1. To tokenize them after making all the terms in lowercase \n",
    "    For each term in the tokenized sentence:\n",
    "    2. Check if the term is in the list of valid words (valid_words_set).\n",
    "    3. If yes, return the word as is.\n",
    "    4. If no, get the correct word using get_correct_term function.\n",
    "    5. To return the joined string as output.\n",
    "    9. Test the function for the input sentence “The new abacos is great”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54e078fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to C:\\Users\\Abhisek\n",
      "[nltk_data]     Das\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 2 - First 20 words:\n",
      "['skelderdrake', 'wrencher', 'lixive', 'Jamnia', 'anteprohibition', 'hepatopneumonic', 'ostracism', 'teethily', 'toyishly', 'hypnotically', 'gnosticizer', 'engild', 'plowline', 'francium', 'sidebones', 'bantayan', 'unbenefitable', 'oilman', 'Gorkiesque', 'Necrophorus']\n",
      "Task 9 - Corrected Sentence: the new abac is great\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import words, stopwords\n",
    "from nltk.metrics import edit_distance\n",
    "from string import punctuation\n",
    "\n",
    "# Task 1: Get a list of valid words in the English language\n",
    "nltk.download('words')\n",
    "valid_words = set(words.words())\n",
    "\n",
    "# Task 2: Look at the first 20 words in the list. Is the casing normalized?\n",
    "print(\"Task 2 - First 20 words:\")\n",
    "print(list(valid_words)[:20])\n",
    "\n",
    "# Task 3: Normalize the casing for all the terms\n",
    "normalized_valid_words = set(word.lower() for word in valid_words)\n",
    "\n",
    "# Task 4: Create a unique list after normalizing\n",
    "unique_normalized_valid_words = list(normalized_valid_words)\n",
    "\n",
    "# Task 5: Create a list of stop words\n",
    "stop_words = set(stopwords.words('english') + list(punctuation))\n",
    "\n",
    "# Task 6: Define a function to get correct a single term\n",
    "def get_correct_term(term):\n",
    "    # Use the first 20,000 entries in the valid word list\n",
    "    subset_valid_words = list(valid_words)[:20000]\n",
    "    \n",
    "    # Store edit distances in a dictionary\n",
    "    edit_distances = {word: edit_distance(term, word) for word in subset_valid_words}\n",
    "    \n",
    "    # Sort the dictionary by edit distances\n",
    "    sorted_distances = sorted(edit_distances.items(), key=lambda x: x[1])\n",
    "    \n",
    "    # Return the correct word with the minimum edit distance\n",
    "    return sorted_distances[0][0]\n",
    "\n",
    "# Task 7: Make a set from the list of valid words\n",
    "valid_words_set = set(valid_words)\n",
    "\n",
    "# Task 8: Define a function for spelling correction\n",
    "def correct_spelling(sentence):\n",
    "    # Tokenize and make all terms lowercase\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    tokens_lower = [token.lower() for token in tokens]\n",
    "\n",
    "    # Check and correct each term\n",
    "    corrected_tokens = [token if token in valid_words_set else get_correct_term(token) for token in tokens_lower]\n",
    "\n",
    "    # Return the joined string as output\n",
    "    return ' '.join(corrected_tokens)\n",
    "\n",
    "# Task 9: Test the function for the input sentence\n",
    "input_sentence = \"The new abacos is great\"\n",
    "output_sentence = correct_spelling(input_sentence)\n",
    "print(\"Task 9 - Corrected Sentence:\", output_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fa0c79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994b2c1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
